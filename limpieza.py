# -*- coding: utf-8 -*-
"""PY2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15LgrzyPaufvUM-K4Tif0K46gItTbvSn7
"""

import pandas as pd
import numpy as np

# Leer el archivo CSV
df = pd.read_csv("data_prueba_proyecto2.csv")

df.info()
df.describe()

# -------------------------- AQUÍ EMPIEZA LA LIMPIEZA --------------------------

# 1. TIPO CORRECTO DE LOS DATOS

# Columnas numéricas para el análisis
cols_numericas = [
    'frecuencia_compra',
    'monto_total_gastado',
    'monto_promedio_compra',
    'dias_desde_ultima_compra',
    'antiguedad_cliente_meses',
    'numero_productos_distintos'
]

# Convertir columnas a numérico (errores → NaN)
for col in cols_numericas:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Convertir columnas a string
df['canal_principal'] = df['canal_principal'].astype("string")
df['texto_reseña'] = df['texto_reseña'].astype("string")
df['producto_categoria'] = df['producto_categoria'].astype("string")

# 2. ELIMINACIÓN DE DUPLICADOS POR cliente_id y reseña_id

df = df.drop_duplicates(subset=[
    'cliente_id',
    'reseña_id'
])

# 3. LIMPIEZA DE VARIABLES

# FRECUENCIA COMPRA

df.loc[df['frecuencia_compra'] < 0, 'frecuencia_compra'] = np.nan

q1 = df['frecuencia_compra'].quantile(0.25)
q3 = df['frecuencia_compra'].quantile(0.75)
iqr = q3 - q1

limite_superior = q3 + 1.5 * iqr

df.loc[df['frecuencia_compra'] > limite_superior, 'frecuencia_compra'] = np.nan

# 3. LIMPIEZA DE VARIABLES

# MONTO TOTAL GASTADO

df.loc[df['monto_total_gastado'] < 0, 'monto_total_gastado'] = np.nan

q1 = df['monto_total_gastado'].quantile(0.25)
q3 = df['monto_total_gastado'].quantile(0.75)
iqr = q3 - q1

limite_superior = q3 + 3.0 * iqr

df.loc[df['monto_total_gastado'] > limite_superior, 'monto_total_gastado'] = np.nan

# 3. LIMPIEZA DE VARIABLES

# MONTO PROMEDIO COMPRA

df.loc[df['monto_promedio_compra'] < 0, 'monto_promedio_compra'] = np.nan

q1 = df['monto_promedio_compra'].quantile(0.25)
q3 = df['monto_promedio_compra'].quantile(0.75)
iqr = q3 - q1

limite_superior = q3 + 1.5 * iqr

df.loc[df['monto_promedio_compra'] > limite_superior, 'monto_promedio_compra'] = np.nan

# 3. LIMPIEZA DE VARIABLES

# DIAS DESDE ULTIMA COMPRA

df.loc[df['dias_desde_ultima_compra'] < 0, 'dias_desde_ultima_compra'] = np.nan

p95 = df["dias_desde_ultima_compra"].quantile(0.95)

df.loc[df["dias_desde_ultima_compra"] > p95, "dias_desde_ultima_compra"] = p95

# 3. LIMPIEZA DE VARIABLES

# ANTIGUEDAD CLIENTE MESES

df.loc[df['antiguedad_cliente_meses'] < 0, 'antiguedad_cliente_meses'] = np.nan

q1 = df['antiguedad_cliente_meses'].quantile(0.25)
q3 = df['antiguedad_cliente_meses'].quantile(0.75)
iqr = q3 - q1

limite_superior = q3 + 3 * iqr

df.loc[
    df['antiguedad_cliente_meses'] > limite_superior,
    'antiguedad_cliente_meses'
] = np.nan

# 3. LIMPIEZA DE VARIABLES

# CANAL PRINCIPAL

df['canal_principal'] = df['canal_principal'].str.strip().str.lower()

# 3. LIMPIEZA DE VARIABLES

# NUMERO PRODUCTOS DISTINTOS

df.loc[df['numero_productos_distintos'] < 0, 'numero_productos_distintos'] = np.nan

# 2. Detección de outliers (IQR - límite superior)
q1 = df['numero_productos_distintos'].quantile(0.25)
q3 = df['numero_productos_distintos'].quantile(0.75)
iqr = q3 - q1

limite_superior = q3 + 1.5 * iqr

df.loc[
    df['numero_productos_distintos'] > limite_superior,
    'numero_productos_distintos'
] = np.nan

# 3. LIMPIEZA DE VARIABLES

# RESEÑA ID

df['reseña_id'] = pd.to_numeric(df['reseña_id'], errors='coerce')

df.loc[df['reseña_id'] <= 0, 'reseña_id'] = np.nan

# 3. LIMPIEZA DE VARIABLES

# TEXTO RESEÑA

df['texto_reseña'] = (
    df['texto_reseña']
    .str.strip()
    .str.lower()
)
df = df[df['texto_reseña'].notna() & (df['texto_reseña'] != "")]

# 3. LIMPIEZA DE VARIABLES

# FECHA RESEÑA

df['fecha_reseña'] = pd.to_datetime(df['fecha_reseña'], errors='coerce')

# 3. LIMPIEZA DE VARIABLES

# PRODUCTO CATEGORIA

df['producto_categoria'] = df['producto_categoria'].str.strip().str.lower()

# 3. LIMPIEZA DE VARIABLES

# LONGITUD RESEÑA

df['longitud_reseña'] = df['texto_reseña'].str.split().str.len()

df['longitud_reseña'] = pd.to_numeric(
    df['longitud_reseña'],
    errors='coerce'
)

# 4. IMPUTACIÓN O ELIMINACIÓN

# CLIENTE ID

df = df[df['cliente_id'].notna()]

# 4. IMPUTACIÓN O ELIMINACIÓN

# FRECUENCIA COMPRA

mediana_frecuencia = df['frecuencia_compra'].median()
df['frecuencia_compra'] = df['frecuencia_compra'].fillna(mediana_frecuencia)

# 4. IMPUTACIÓN O ELIMINACIÓN

# MONTO TOTAL GASTADO

mediana_monto_total = df['monto_total_gastado'].median()
df['monto_total_gastado'] = df['monto_total_gastado'].fillna(mediana_monto_total)

# 4. IMPUTACIÓN O ELIMINACIÓN

# MONTO PROMEDIO COMPRA

mediana_monto_promedio = df['monto_promedio_compra'].median()
df['monto_promedio_compra'] = df['monto_promedio_compra'].fillna(mediana_monto_promedio)

# 4. IMPUTACIÓN O ELIMINACIÓN

# DIAS DESDE ULTIMA COMPRA

mediana_dias = df['dias_desde_ultima_compra'].median()
df['dias_desde_ultima_compra'] = df['dias_desde_ultima_compra'].fillna(mediana_dias)

# 4. IMPUTACION O ELIMINACIÓN

# ANTIGUEDAD CLIENTE MESES

mediana_antiguedad = df['antiguedad_cliente_meses'].median()
df['antiguedad_cliente_meses'] = df['antiguedad_cliente_meses'].fillna(mediana_antiguedad)

# 4. IMPUTACION O ELIMINACIÓN

# NUMERO PRODUCTOS DISTINTOS

mediana_productos = df['numero_productos_distintos'].median()
df['numero_productos_distintos'] = df['numero_productos_distintos'].fillna(mediana_productos)

# 4. IMPUTACION O ELIMINACIÓN

# RESEÑA ID

df = df[df['reseña_id'].notna()]

df.info()
df.describe()



# -------------------------- ENTRENAMIENTO (CLUSTERING) NUMÉRICO --------------------------

"""# CLUSTERING (NUMÉRICO)"""

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import (
    silhouette_score,
    calinski_harabasz_score,
    davies_bouldin_score
)

# Columnas numéricas que usarás para clustering de clientes
cols_cluster_numerico = [
    'frecuencia_compra',
    'monto_total_gastado',
    'monto_promedio_compra',
    'dias_desde_ultima_compra',
    'antiguedad_cliente_meses',
    'numero_productos_distintos'
]

# Matriz numérica
X_num = df[cols_cluster_numerico].copy()

# Normalización (importante para K-Means)
scaler = StandardScaler()
X_num_scaled = scaler.fit_transform(X_num)

# Elegir K (manual)
k_num = 6

# Elegir (manual)
max_iter_num = 300

kmeans_num = KMeans(
    n_clusters = k_num,
    max_iter = max_iter_num,
    random_state = 42,
    n_init = 10
)

# HIPERPARÁMETROS QUE TIENEN QUE COLOCAR 
# NÚMERO DE CLUSTERS (K) RANGO: 2 A 100
# MÁXIMAS ITERACIONES (max_iter) RANGO 100 A 500
# NÚMERO DE REINICIOS (n_init) RANGO 5 A 30

clusters_num = kmeans_num.fit_predict(X_num_scaled)

df['cluster_clientes'] = clusters_num

# Métricas
sil_num = silhouette_score(X_num_scaled, clusters_num)
inercia_num = kmeans_num.inertia_
ch_num = calinski_harabasz_score(X_num_scaled, clusters_num)
db_num = davies_bouldin_score(X_num_scaled, clusters_num)



# -------------------------- MÉTRICAS QUE HAY QUE MOSTRAR --------------------------
print("=== CLUSTERING NUMÉRICO (CLIENTES) ===")
print("K (manual) =", k_num)
print("Silhouette:", sil_num)
print("Inercia:", inercia_num)
print("Calinski-Harabasz:", ch_num)
print("Davies-Bouldin:", db_num)

# Perfil rápido por cluster (promedios por grupo)
perfil_clientes = df.groupby('cluster_clientes')[cols_cluster_numerico].mean()
print("\nPerfil por cluster (promedios):")
print(perfil_clientes)

